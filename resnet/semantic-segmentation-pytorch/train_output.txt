Input arguments:
id               train1
arch_encoder     resnet50_dilated8
arch_decoder     ppm_bilinear_deepsup
weights_encoder  
weights_decoder  
fc_dim           2048
list_train       /home/ky_aneur/cs230/code/cta-scripts/train_list.odgt
list_val         ./data/validation.odgt
root_dataset     /data2/yeom/ky_aneur/sah_png/train
num_gpus         2
batch_size_per_gpu 2
num_epoch        1
start_epoch      1
epoch_iters      500
optim            adam
lr_encoder       0.02
lr_decoder       0.02
lr_pow           0.9
beta1            0.9
weight_decay     0.0001
deep_sup_scale   0.4
fix_bn           0
num_class        2
workers          16
imgSize          [300, 375, 450, 525, 600]
imgMaxSize       1000
padding_constant 8
segm_downsampling_rate 8
random_flip      True
seed             304
ckpt             ./ckpt
disp_iter        20
Model ID: train1-resnet50_dilated8-ppm_bilinear_deepsup-ngpus2-batchSize4-imgMaxSize1000-paddingConst8-segmDownsampleRate8-LR_encoder0.02-LR_decoder0.02-epoch1-decay0.0001-fixBN0
# samples: 6483
1 Epoch = 500 iters
Epoch: [1][0/500], Time: 4.25, Data: 0.14, lr_encoder: 0.020000, lr_decoder: 0.020000, Accuracy: 0.00, Loss: 0.000000
Epoch: [1][20/500], Time: 0.83, Data: 0.06, lr_encoder: 0.019315, lr_decoder: 0.019315, Accuracy: 7.14, Loss: 0.027908
Epoch: [1][40/500], Time: 0.72, Data: 0.05, lr_encoder: 0.018590, lr_decoder: 0.018590, Accuracy: 4.88, Loss: 0.014294
Epoch: [1][60/500], Time: 0.69, Data: 0.05, lr_encoder: 0.017863, lr_decoder: 0.017863, Accuracy: 4.10, Loss: 0.009608
Epoch: [1][80/500], Time: 0.68, Data: 0.05, lr_encoder: 0.017132, lr_decoder: 0.017132, Accuracy: 3.70, Loss: 0.007235
Epoch: [1][100/500], Time: 0.68, Data: 0.05, lr_encoder: 0.016398, lr_decoder: 0.016398, Accuracy: 3.47, Loss: 0.005803
Epoch: [1][120/500], Time: 0.67, Data: 0.05, lr_encoder: 0.015660, lr_decoder: 0.015660, Accuracy: 2.89, Loss: 0.004844
Epoch: [1][140/500], Time: 0.68, Data: 0.05, lr_encoder: 0.014918, lr_decoder: 0.014918, Accuracy: 2.48, Loss: 0.004157
Epoch: [1][160/500], Time: 0.68, Data: 0.05, lr_encoder: 0.014172, lr_decoder: 0.014172, Accuracy: 3.42, Loss: 0.003641
Epoch: [1][180/500], Time: 0.68, Data: 0.05, lr_encoder: 0.013422, lr_decoder: 0.013422, Accuracy: 3.31, Loss: 0.003241
Epoch: [1][200/500], Time: 0.68, Data: 0.05, lr_encoder: 0.012667, lr_decoder: 0.012667, Accuracy: 2.99, Loss: 0.002919
Epoch: [1][220/500], Time: 0.68, Data: 0.05, lr_encoder: 0.011907, lr_decoder: 0.011907, Accuracy: 2.94, Loss: 0.002655
Epoch: [1][240/500], Time: 0.68, Data: 0.05, lr_encoder: 0.011141, lr_decoder: 0.011141, Accuracy: 3.32, Loss: 0.002437
Epoch: [1][260/500], Time: 0.68, Data: 0.05, lr_encoder: 0.010370, lr_decoder: 0.010370, Accuracy: 3.45, Loss: 0.002259
Epoch: [1][280/500], Time: 0.68, Data: 0.05, lr_encoder: 0.009592, lr_decoder: 0.009592, Accuracy: 3.38, Loss: 0.002098
Epoch: [1][300/500], Time: 0.68, Data: 0.05, lr_encoder: 0.008807, lr_decoder: 0.008807, Accuracy: 3.32, Loss: 0.001959
Epoch: [1][320/500], Time: 0.68, Data: 0.05, lr_encoder: 0.008014, lr_decoder: 0.008014, Accuracy: 3.27, Loss: 0.001836
Epoch: [1][340/500], Time: 0.69, Data: 0.05, lr_encoder: 0.007213, lr_decoder: 0.007213, Accuracy: 3.23, Loss: 0.001729
Epoch: [1][360/500], Time: 0.69, Data: 0.05, lr_encoder: 0.006401, lr_decoder: 0.006401, Accuracy: 3.19, Loss: 0.001633
Epoch: [1][380/500], Time: 0.68, Data: 0.05, lr_encoder: 0.005578, lr_decoder: 0.005578, Accuracy: 3.15, Loss: 0.001548
Epoch: [1][400/500], Time: 0.68, Data: 0.05, lr_encoder: 0.004741, lr_decoder: 0.004741, Accuracy: 3.12, Loss: 0.001471
Epoch: [1][420/500], Time: 0.68, Data: 0.05, lr_encoder: 0.003887, lr_decoder: 0.003887, Accuracy: 3.09, Loss: 0.001401
Epoch: [1][440/500], Time: 0.68, Data: 0.05, lr_encoder: 0.003011, lr_decoder: 0.003011, Accuracy: 2.95, Loss: 0.001337
Epoch: [1][460/500], Time: 0.68, Data: 0.05, lr_encoder: 0.002106, lr_decoder: 0.002106, Accuracy: 3.04, Loss: 0.001279
Epoch: [1][480/500], Time: 0.68, Data: 0.05, lr_encoder: 0.001153, lr_decoder: 0.001153, Accuracy: 2.91, Loss: 0.001226
Saving checkpoints...
Training Done!
